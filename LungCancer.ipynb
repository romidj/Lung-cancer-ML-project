{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romidj/Lung-cancer-ML-project/blob/main/LungCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ofeS0yFLjmx"
      },
      "source": [
        "#Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H7rFwXQh5fuK"
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Model selection & tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkwXy2SgKvx"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "Hb3UqqPB5fuL",
        "outputId": "1549c0a3-3ed3-45a2-89ec-f4bdad783e34"
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xa0 in position 339: invalid start byte",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0db92fe67460>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load Our Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dataset (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 339: invalid start byte"
          ]
        }
      ],
      "source": [
        "#Load Our Dataset\n",
        "train = pd.read_csv('/content/dataset.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16aXrnaKm0Pc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR650aFD5fuN"
      },
      "source": [
        "#### Desribe the Datafrme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqPsMMfd5fuN"
      },
      "outputs": [],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxVJmHEv5fuN"
      },
      "outputs": [],
      "source": [
        "train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cScGBJJ5fuO"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhvWd-WY5fuO"
      },
      "outputs": [],
      "source": [
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCUfHxKGu3l3"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtmD_tU8gk0g"
      },
      "source": [
        "# Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es0kosJp5fuP"
      },
      "source": [
        "#### Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux3TERvt5fuP"
      },
      "outputs": [],
      "source": [
        "### Drop unusefull features\n",
        "train = train.drop(columns=['id', 'country', 'occupation_type', 'education_level', 'marital_status', 'diet_type', 'bmi', 'diagnosis_date','end_treatment_date' ], errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lovuo8Go5fuP"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FslnT7Nj6qS7"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIayW1yy5fuQ"
      },
      "outputs": [],
      "source": [
        "##Fill Missing Values in \"age\"\n",
        "#plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(train['age'], bins=30, color='blue', alpha=0.7)\n",
        "plt.title('Histogram of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULdlGv2U5fuQ"
      },
      "outputs": [],
      "source": [
        "# Scatter plot for 'age'\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train.index, train['age'], color='blue', alpha=0.5)\n",
        "plt.title('Scatter Plot for Age')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Age')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7SDZl365fuR"
      },
      "outputs": [],
      "source": [
        "age_median = train['age'].median()\n",
        "train['age'] = train['age'].fillna(age_median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WniTWNEY5fuR"
      },
      "outputs": [],
      "source": [
        "train['gender'] = train['gender'].str.strip().str.lower()\n",
        "sns.countplot(x='gender', data=train, palette='Blues')\n",
        "plt.title('Bar Plot for Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43nPPOqL5fuR"
      },
      "outputs": [],
      "source": [
        "# Remplacer les erreurs courantes\n",
        "train['gender'] = train['gender'].replace({\n",
        "    'malee': 'male',\n",
        "    'email': 'male',  # ou 'female' selon le contexte\n",
        "    'feemale': 'female',\n",
        "    'femal': 'female',\n",
        "    'femal': 'female'  # Autres erreurs à traiter\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qolSDS4z5fuS"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='gender', data=train, palette='Blues')\n",
        "plt.title('Bar Plot for Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E31VmZC5fuT"
      },
      "outputs": [],
      "source": [
        "most_frequent_gender = train['gender'].mode()[0]\n",
        "train['gender'].fillna(most_frequent_gender, inplace=True)\n",
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb2ebKoE5fuT"
      },
      "outputs": [],
      "source": [
        "# Set the figure size (width, height)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the count plot for cancer stages\n",
        "sns.countplot(x='cancer_stage', data=train, palette='Set1')\n",
        "\n",
        "# Set title and labels\n",
        "plt.title('Frequency of Cancer Stages', fontsize=16)\n",
        "plt.xlabel('Cancer Stage', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Tv6M8f5fuT"
      },
      "outputs": [],
      "source": [
        "print(train['cancer_stage'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ_pnasD5fuT"
      },
      "outputs": [],
      "source": [
        "# Standardize the 'cancer_stage' column values\n",
        "train['cancer_stage'] = train['cancer_stage'].replace({\n",
        "    'Stage I': 'Stage 1', 'stage one': 'Stage 1', 'Stage 1': 'Stage 1',\n",
        "    'Stage II': 'Stage 2', 'stage two': 'Stage 2', 'Stage 2': 'Stage 2',\n",
        "    'Stage III': 'Stage 3', 'stage three': 'Stage 3', 'Stage 3': 'Stage 3',\n",
        "    'Stage IV': 'Stage 4', 'stage four': 'Stage 4', 'Stage 4': 'Stage 4'\n",
        "})\n",
        "\n",
        "# Check the standardized values to ensure correct replacement\n",
        "print(train['cancer_stage'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7em20utA5fuU"
      },
      "outputs": [],
      "source": [
        "# Nettoyage de la colonne 'cancer_stage'\n",
        "train['cancer_stage'] = train['cancer_stage'].str.strip()  # Supprime les espaces autour des valeurs\n",
        "train['cancer_stage'].replace('', None, inplace=True)      # Remplace les chaînes vides par None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eff5CkbY5fuU"
      },
      "outputs": [],
      "source": [
        "# Set the figure size (width, height)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the count plot for cancer stages\n",
        "sns.countplot(x='cancer_stage', data=train, palette='Set1')\n",
        "\n",
        "# Set title and labels\n",
        "plt.title('Frequency of Cancer Stages', fontsize=16)\n",
        "plt.xlabel('Cancer Stage', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS203rVD5fuU"
      },
      "outputs": [],
      "source": [
        "mode_value = train['cancer_stage'].mode()[0]  # Calcule la mode\n",
        "train['cancer_stage'].fillna(mode_value, inplace=True)  # Remplit les valeurs manquantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZCrW4Wc5fuU"
      },
      "outputs": [],
      "source": [
        "train['cancer_stage'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SngASTJGT6B"
      },
      "outputs": [],
      "source": [
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUuBAQqf5fuU"
      },
      "outputs": [],
      "source": [
        "train['smoking_status'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_MDjwpS5fuV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "train['smoking_status'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribution of Smoking Status')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zafyxvEi5fuV"
      },
      "outputs": [],
      "source": [
        "train['smoking_status'] = train['smoking_status'].fillna(train['smoking_status'].mode()[0])\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh-LBpgQ5fuV"
      },
      "outputs": [],
      "source": [
        "# Plot the distribution of cholesterol_level\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(train['cholesterol_level'], kde=True, bins=30, color='blue')\n",
        "plt.title('Distribution of Cholesterol Levels')\n",
        "plt.xlabel('Cholesterol Level')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3B8niPS5fuW"
      },
      "outputs": [],
      "source": [
        "# Fill missing values in 'cholesterol_level' with the median\n",
        "train['cholesterol_level'].dtypes\n",
        "train['cholesterol_level'] = train['cholesterol_level'].fillna(train['cholesterol_level'].median())\n",
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT5li4Xb5fuW"
      },
      "outputs": [],
      "source": [
        "train['treatment_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-AQ6yq45fuW"
      },
      "outputs": [],
      "source": [
        "# Uniformiser la casse pour toutes les valeurs de 'treatment_type'\n",
        "train['treatment_type'] = train['treatment_type'].str.capitalize()\n",
        "\n",
        "# Remplacer les valeurs incorrectes par les bonnes\n",
        "train['treatment_type'] = train['treatment_type'].replace({\n",
        "    'Surgerie': 'Surgery', 'Sergery': 'Surgery', 'Surgry': 'Surgery',\n",
        "    'Radiaton': 'Radiation', 'Radation': 'Radiation',\n",
        "    'Chemotharapy': 'Chemotherapy', 'Chemoterapy': 'Chemotherapy',\n",
        "    'Combimed': 'Combined', 'Combained': 'Combined'\n",
        "})\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "train['treatment_type'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribution of Treatment Type')\n",
        "plt.xlabel('Treatment Type')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILDSSCZF5fuW"
      },
      "outputs": [],
      "source": [
        "# Remplir les valeurs manquantes dans 'treatment_type' avec la mode\n",
        "train['treatment_type'] = train['treatment_type'].fillna(train['treatment_type'].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5EuSi9lDSGY"
      },
      "outputs": [],
      "source": [
        "# Créer un dictionnaire de mappage pour uniformiser les valeurs\n",
        "mapping = {\n",
        "    '1': 1, 'Yes': 1, 'yes': 1,  # Variations de \"oui\" deviennent 1\n",
        "    '0': 0, 'No': 0, 'no': 0     # Variations de \"non\" deviennent 0\n",
        "}\n",
        "\n",
        "# Appliquer le mappage à la colonne 'cirrhosis'\n",
        "train['cirrhosis'] = train['cirrhosis'].replace(mapping)\n",
        "\n",
        "# Vérifier les valeurs uniques après conversion\n",
        "print(train['cirrhosis'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlZe4ojW5fuX"
      },
      "outputs": [],
      "source": [
        "print(train['comorbidity_score'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2abhIANhk-I"
      },
      "outputs": [],
      "source": [
        "train['comorbidity_score'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTcCf1kIENAn"
      },
      "outputs": [],
      "source": [
        "train['comorbidity_score'] = pd.to_numeric(train['comorbidity_score'], errors='coerce')\n",
        "train['comorbidity_score'] = train['comorbidity_score'].fillna(train['comorbidity_score'].median())\n",
        "print(train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPwGIXCr5fuX"
      },
      "outputs": [],
      "source": [
        "train[\"other_cancer\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JADovTq35fuX"
      },
      "outputs": [],
      "source": [
        "# Créer un dictionnaire de mappage pour uniformiser les valeurs\n",
        "mapping = {\n",
        "    '0': 0, '1': 1,   # Garde '0' et '1' comme entiers\n",
        "    'NON': 0, 'no': 0, 'No': 0,  # Toutes les variations de \"non\" deviennent 0\n",
        "    'yes': 1, 'Yes': 1           # Toutes les variations de \"yes\" deviennent 1\n",
        "}\n",
        "\n",
        "# Appliquer le mappage à la colonne 'other_cancer'\n",
        "train['other_cancer'] = train['other_cancer'].replace(mapping)\n",
        "\n",
        "# Vérifier les valeurs uniques après conversion\n",
        "print(train['other_cancer'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGevIoOI5fud"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04DSuisr5fue"
      },
      "outputs": [],
      "source": [
        "train[\"family_history\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMI0ojK85fue"
      },
      "outputs": [],
      "source": [
        "# Créer un dictionnaire de mappage pour uniformiser les valeurs\n",
        "mapping = {\n",
        "    '1': 1, 'true': 1, 'Yes': 1, 'yes': 1,  # Variations de \"true\" ou \"yes\" deviennent 1\n",
        "    '0': 0, 'False': 0, 'No': 0, 'no': 0    # Variations de \"false\" ou \"no\" deviennent 0\n",
        "}\n",
        "\n",
        "# Appliquer le mappage à la colonne 'family_history'\n",
        "train['family_history'] = train['family_history'].replace(mapping)\n",
        "\n",
        "# Vérifier les valeurs uniques après conversion\n",
        "print(train['family_history'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgSHA_sziImP"
      },
      "outputs": [],
      "source": [
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GVCjIjg5fue"
      },
      "outputs": [],
      "source": [
        "train[\"cirrhosis\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE95l0Ff9Xfl"
      },
      "outputs": [],
      "source": [
        "train = train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTdUPdqY9G4S"
      },
      "outputs": [],
      "source": [
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQjt56WC5fuf"
      },
      "outputs": [],
      "source": [
        "train = train.drop_duplicates()\n",
        "train.shape\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPLZ0xmj5fug"
      },
      "source": [
        "# Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT5XcMyd5fuh"
      },
      "outputs": [],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeYCkg9i5fuj"
      },
      "outputs": [],
      "source": [
        "train['treatment_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0NmyeuHjGHj"
      },
      "outputs": [],
      "source": [
        "#Apply one hot encoding directly on train for the treatment_type column with inplace true\n",
        "train = pd.get_dummies(train, columns=['treatment_type'], prefix=['treatment_type'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5OoOIzWjmTX"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYhAwLTS5fuk"
      },
      "outputs": [],
      "source": [
        "# # Créer un dictionnaire pour mapper les types de traitement\n",
        "# treatment_mapping = {\n",
        "#     'Surgery': 1,\n",
        "#     'Radiation': 2,\n",
        "#     'radiation': 2,  # Corriger les incohérences (comme la casse)\n",
        "#     'Combined': 3,\n",
        "#     'Chemotherapy': 4\n",
        "# }\n",
        "\n",
        "# # Appliquer l'encodage\n",
        "# train['treatment_type_encoded'] = train['treatment_type'].map(treatment_mapping)\n",
        "\n",
        "# # Vérifier les résultats\n",
        "# print(train[['treatment_type', 'treatment_type_encoded']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-0XVZMh5fuk"
      },
      "outputs": [],
      "source": [
        "train['gender'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdcTQUuh5ful"
      },
      "outputs": [],
      "source": [
        "train['gender'] = train['gender'].map({'female': 0, 'male': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFl2dt0F5ful"
      },
      "outputs": [],
      "source": [
        "train['cancer_stage'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iodtPlMZ5fum"
      },
      "outputs": [],
      "source": [
        "# Map the 'cancer_stage' column to numerical values\n",
        "train['cancer_stage'] = train['cancer_stage'].map({\n",
        "    'Stage 1': 1,\n",
        "    'Stage 2': 2,\n",
        "    'Stage 3': 3,\n",
        "    'Stage 4': 4\n",
        "})\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(train[['cancer_stage']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl6nZgMT5fum"
      },
      "outputs": [],
      "source": [
        "train[\"smoking_status\"].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbymsnIB5fun"
      },
      "outputs": [],
      "source": [
        "# Définir un mapping manuel\n",
        "smoking_mapping = {\n",
        "    'Never Smoked': 0,\n",
        "    'Former Smoker': 1,\n",
        "    'Light Smoker (< 10/day)': 2,\n",
        "    'Moderate Smoker (10-20/day)': 3,\n",
        "    'Occasional Smoker': 4,\n",
        "    'Heavy Smoker (> 20/day)': 5\n",
        "}\n",
        "\n",
        "# Remplacer les valeurs dans la colonne\n",
        "train['smoking_status'] = train['smoking_status'].map(smoking_mapping)\n",
        "\n",
        "# Afficher le DataFrame\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOq3RmqrGrqI"
      },
      "outputs": [],
      "source": [
        "print(type(train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5ld62YX1v3-"
      },
      "outputs": [],
      "source": [
        "# Compter les valeurs uniques pour les colonnes catégoriques\n",
        "# Convert the NumPy array back into a Pandas DataFrame to use nunique()\n",
        "train_df = pd.DataFrame(train)\n",
        "print(train_df.nunique()) # Now you can use nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo8f55SiT_wq"
      },
      "outputs": [],
      "source": [
        "# Distribution de la survie par genre\n",
        "gender_survival = train.groupby('gender')['survived'].value_counts(normalize=True).unstack()\n",
        "print(gender_survival)\n",
        "\n",
        "# Visualisation\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='gender', y='survived', data=train, ci=None, palette='Set2')\n",
        "plt.title('Taux de survie par genre')\n",
        "plt.xlabel('Genre (0 = Homme, 1 = Femme)')\n",
        "plt.ylabel('Taux de survie')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hYMC4D6Wjts"
      },
      "source": [
        "Interprétation possible :\n",
        "\n",
        "Les femmes pourraient avoir des facteurs de risque plus élevés ou recevoir des traitements moins efficaces.\n",
        "Les stades de cancer chez les femmes pourraient être plus avancés au moment du diagnostic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ilSDWg0UGOq"
      },
      "outputs": [],
      "source": [
        "# Distribution de la survie par statut de fumeur\n",
        "smoking_survival = train.groupby('smoking_status')['survived'].value_counts(normalize=True).unstack()\n",
        "print(smoking_survival)\n",
        "\n",
        "# Visualisation\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='smoking_status', y='survived', data=train, ci=None, palette='coolwarm')\n",
        "plt.title('Taux de survie par statut de fumeur')\n",
        "plt.xlabel('Statut de fumeur')\n",
        "plt.ylabel('Taux de survie')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuid0oW8Ik"
      },
      "source": [
        "Interprétation possible de ces résultats :\n",
        "Non-fumeurs (0) ont un taux de survie plus élevé que les fumeurs légers (1), modérés (2), etc.\n",
        "Fumeurs modérés et lourds (comme 4, 5, 3) pourraient avoir des taux de survie plus faibles. Cela peut être dû à des complications liées au tabagisme, par exemple, qui affectent la santé globale, rendant les patients plus vulnérables à des traitements moins efficaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h38bMoomULKL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='survived', y='comorbidity_score', data=train, palette='pastel')\n",
        "plt.title('Score de comorbidité par statut de survie')\n",
        "plt.xlabel('Survived (0 = Non, 1 = Oui)')\n",
        "plt.ylabel('Score de comorbidité')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR4K-jucUSfu"
      },
      "outputs": [],
      "source": [
        "# # Distribution de la survie par type de traitement\n",
        "# treatment_survival = train.groupby('treatment_type')['survived'].mean()\n",
        "# print(treatment_survival)\n",
        "\n",
        "# # Visualisation\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.barplot(x='treatment_type', y='survived', data=train, ci=None, palette='viridis')\n",
        "# plt.title('Taux de survie par type de traitement')\n",
        "# plt.xlabel('Type de traitement')\n",
        "# plt.ylabel('Taux de survie')\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GeZGJk1XKKw"
      },
      "source": [
        "Interprétation possible :\n",
        "Traitement 3 (Combined) a le taux de survie le plus élevé. Cela pourrait indiquer qu'un traitement combiné (qui inclut plusieurs modalités de traitement) est plus efficace que les traitements individuels dans ce jeu de données.\n",
        "Traitement 2 (Radiation) et Traitement 1 (Surgery) viennent ensuite, suggérant que la combinaison de radiation ou de chirurgie, même si elles sont efficaces, ne sont pas aussi efficaces que le traitement combiné.\n",
        "Traitement 4 (Chemotherapy) a le taux de survie le plus bas, ce qui pourrait suggérer que, dans ce contexte particulier, la chimiothérapie n'a pas été aussi efficace, ou bien que les patients ayant reçu ce traitement étaient plus gravement malades au départ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfqwlHwVUXeY"
      },
      "outputs": [],
      "source": [
        "# Asthme\n",
        "asthma_survival = train.groupby('asthma')['survived'].mean()\n",
        "print(\"Taux de survie par asthme :\\n\", asthma_survival)\n",
        "\n",
        "# Hypertension\n",
        "hypertension_survival = train.groupby('hypertension')['survived'].mean()\n",
        "print(\"Taux de survie par hypertension :\\n\", hypertension_survival)\n",
        "\n",
        "# Visualisation combinée\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x='asthma', y='survived', data=train, ci=None, palette='Blues')\n",
        "plt.title('Taux de survie par asthme')\n",
        "plt.xlabel('Asthme (0 = Non, 1 = Oui)')\n",
        "plt.ylabel('Taux de survie')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x='hypertension', y='survived', data=train, ci=None, palette='Greens')\n",
        "plt.title('Taux de survie par hypertension')\n",
        "plt.xlabel('Hypertension (0 = Non, 1 = Oui)')\n",
        "plt.ylabel('Taux de survie')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ZpV-_sXlhe"
      },
      "source": [
        "Asthme :\n",
        "Taux de survie pour ceux sans asthme (asthma=0) est plus élevé que pour ceux ayant de l'asthme (asthma=1).\n",
        "Cela pourrait suggérer que l'absence d'asthme est associée à un taux de survie plus élevé, ce qui pourrait être dû à des complications liées à l'asthme qui rendent les patients plus vulnérables.\n",
        "Interprétation :\n",
        "Cela peut sembler surprenant au premier abord, mais voici quelques explications possibles :\n",
        "Soins médicaux plus rigoureux : Les patients ayant de l'hypertension peuvent bénéficier d'une surveillance médicale plus étroite, avec des médicaments prescrits et des consultations régulières pour contrôler leur pression artérielle, ce qui pourrait améliorer leur état général et augmenter leur survie.\n",
        "Autres comorbidités ou traitements associés : Les patients atteints d'hypertension peuvent avoir des traitements ou des soins spécifiques qui contribuent également à leur survie, comme des traitements pour d'autres problèmes cardiovasculaires ou des interventions spécifiques à l'hypertension.\n",
        "Facteurs d'âge ou de mode de vie : Les personnes plus âgées ou ayant d'autres conditions peuvent aussi être diagnostiquées avec de l'hypertension, et ces facteurs peuvent interagir avec d'autres aspects de leur santé pour influencer leur taux de survie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un3ZXqbGj2F9"
      },
      "source": [
        "# Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3uqC-kV5fug"
      },
      "outputs": [],
      "source": [
        "### Plot of distribution of data\n",
        "train.hist(bins=50,figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV-jAjt15fun"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "#Apply for all the data\n",
        "train= pd.DataFrame(scaler.fit_transform(train),\n",
        "                           columns=train.columns,\n",
        "                           index=train.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmGzvoLq5fuw"
      },
      "source": [
        "# Data modeling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi9y9Cbz5fuw"
      },
      "outputs": [],
      "source": [
        "# Sélectionner les colonnes pertinentes\n",
        "features = train.drop(columns=['survived'])\n",
        "target = train['survived']\n",
        "\n",
        "# S'assurer qu'il n'y a pas de valeurs manquantes\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Vérification des dimensions\n",
        "print(features.shape, target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d92Zil615fuw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensions de l'ensemble d'entraînement :\", X_train.shape, y_train.shape)\n",
        "print(\"Dimensions de l'ensemble de test :\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54LaJVh2mLDR"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcvbBRARmJid"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeqnsPqP3m7W"
      },
      "outputs": [],
      "source": [
        "# Tester plusieurs valeurs de k\n",
        "errors = []\n",
        "k_values = list(range(1, 31))\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_k = knn.predict(X_test)\n",
        "    acc = accuracy_score(y_test, pred_k)\n",
        "    errors.append(1 - acc)  # erreur = 1 - accuracy\n",
        "\n",
        "# Graphique\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(k_values, errors, color='blue', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='red', markersize=8)\n",
        "plt.title('Erreur vs. Valeur de K')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Erreur')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T4iz3Hr3_2g"
      },
      "outputs": [],
      "source": [
        "best_k = k_values[np.argmin(errors)]\n",
        "print(\"Best k:\", best_k)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNeiHTH04Bwy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Probabilités pour ROC\n",
        "y_prob = knn.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - KNN')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvs6O22lnPK0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS4tB-ymnUup"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(n_neighbors=best_k), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "# Get the best model\n",
        "best_knn_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhRlTymhoXBP"
      },
      "outputs": [],
      "source": [
        "#print the results using the best hyperparameters\n",
        "y_pred_best = best_knn_model.predict(X_test)\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "precision_best = precision_score(y_test, y_pred_best)\n",
        "recall_best = recall_score(y_test, y_pred_best)\n",
        "f1_best = f1_score(y_test, y_pred_best)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_best}\")\n",
        "print(f\"Precision: {precision_best}\")\n",
        "print(f\"Recall: {recall_best}\")\n",
        "print(f\"F1-Score: {f1_best}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcuzwsoHoKIB"
      },
      "outputs": [],
      "source": [
        "#conf matrix\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix_best}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLSKAHl9ml3w"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgOx2_0B5fuw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV  # Pour validation croisee et recherche d'hyperparamètres\n",
        "# Initialiser le modèle\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Entraîner le modèle\n",
        "model.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y88NQH7e5fux"
      },
      "outputs": [],
      "source": [
        "# ==================== Cellule 1 : Recherche des meilleurs hyperparamètres ====================\n",
        "\n",
        "# Définir la grille des hyperparamètres à tester\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Nombre d'arbres dans la forêt\n",
        "    'max_depth': [None, 10, 20, 30],  # Profondeur maximale des arbres\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum d'échantillons pour diviser un noeud\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum d'échantillons dans une feuille\n",
        "}\n",
        "\n",
        "# Initialiser un modèle de base RandomForest\n",
        "base_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Utiliser GridSearchCV pour tester toutes les combinaisons possibles\n",
        "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "\n",
        "# Lancer la recherche sur les données d'entraînement\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Afficher les meilleurs hyperparamètres trouvés\n",
        "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEw1Qw1qONL0"
      },
      "outputs": [],
      "source": [
        "# ==================== Cellule 2 : Entraînement du meilleur modèle ====================\n",
        "\n",
        "# Récupérer le meilleur modèle obtenu\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Entraîner le modèle optimisé sur tout l'ensemble d'entraînement\n",
        "best_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyQZ9JvCOYyN"
      },
      "outputs": [],
      "source": [
        "# ==================== Cellule 3 : Prédiction et évaluation ====================\n",
        "\n",
        "# Prédire les étiquettes sur l'ensemble de test\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculer l'exactitude (Accuracy)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Créer la matrice de confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Générer un rapport de classification\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(\"\\nExactitude (Accuracy) :\", accuracy)\n",
        "print(\"\\nMatrice de confusion :\\n\", conf_matrix)\n",
        "print(\"\\nRapport de classification :\\n\", class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t83vlmUpOZ9_"
      },
      "outputs": [],
      "source": [
        "# Calculer la courbe d'apprentissage (train/validation)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    best_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42\n",
        ")\n",
        "\n",
        "# Calculer la moyenne et l'écart-type pour chaque taille d'échantillon\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
        "valid_scores_std = np.std(valid_scores, axis=1)\n",
        "\n",
        "# Créer le graphique\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Courbe d'apprentissage du Random Forest optimisé\")\n",
        "plt.xlabel(\"Taille de l'ensemble d'apprentissage\")\n",
        "plt.ylabel(\"Exactitude (Accuracy)\")\n",
        "plt.grid()\n",
        "\n",
        "# Remplir entre les intervalles (moyenne ± std) pour visualiser l'incertitude\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std,\n",
        "                 valid_scores_mean + valid_scores_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "# Tracer la courbe de performance sur les données d'entraînement\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Score d'entraînement\")\n",
        "\n",
        "# Tracer la courbe de performance sur les données de validation croisée\n",
        "plt.plot(train_sizes, valid_scores_mean, 'o-', color=\"g\", label=\"Score de validation croisée\")\n",
        "\n",
        "# Ajouter la légende\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "# Afficher la courbe\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1tbs5Wqe_5L"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FmBtknfGiGeK",
        "outputId": "91ec5294-9a16-4ba1-ac56-6fccebdc7d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Kernel: linear ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.88      0.87     52405\n",
            "         1.0       0.80      0.79      0.79     33995\n",
            "\n",
            "    accuracy                           0.84     86400\n",
            "   macro avg       0.83      0.83      0.83     86400\n",
            "weighted avg       0.84      0.84      0.84     86400\n",
            "\n",
            "\n",
            "--- Kernel: rbf ---\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "f1_scores = {}\n",
        "\n",
        "for kernel in kernels:\n",
        "    print(f\"\\n--- Kernel: {kernel} ---\")\n",
        "\n",
        "    # Si kernel='poly', on essaiera plusieurs degrés après\n",
        "    # Only set degree for 'poly' kernel, otherwise leave it to default\n",
        "    if kernel == 'poly':\n",
        "        degree_values = [2, 3, 4]\n",
        "        for degree in degree_values:\n",
        "            print(f\"\\n  > Degree: {degree}\")\n",
        "            clf = SVC(kernel=kernel, degree=degree)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "\n",
        "            print(classification_report(y_test, y_pred))\n",
        "            f1_scores[f\"{kernel}_deg{degree}\"] = f1_score(y_test, y_pred, average='binary')  # or 'weighted'/'binary' as appropriate\n",
        "    else:\n",
        "        clf = SVC(kernel=kernel)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    f1_scores[kernel] = f1_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpnW9mVwi3yZ"
      },
      "outputs": [],
      "source": [
        "f1_summary = pd.DataFrame.from_dict(f1_scores, orient='index', columns=['F1 Score'])\n",
        "f1_summary = f1_summary.sort_values(by='F1 Score', ascending=False)\n",
        "print(\"\\nRésumé des F1-scores :\\n\", f1_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrpyHLXbWS0_"
      },
      "outputs": [],
      "source": [
        "# Simple F1 score comparison plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(f1_scores.keys(), f1_scores.values(), color='skyblue')\n",
        "plt.title('F1 Score Comparison of SVM Kernels')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('Kernel / Degree')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_rfLGxwUA7U"
      },
      "outputs": [],
      "source": [
        "# Apply PCA to reduce to 2D\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_train)\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_train, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit the SVM with a linear kernel\n",
        "clf = SVC(kernel='linear', C=1)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-59vittQSmbB"
      },
      "outputs": [],
      "source": [
        "# Plot decision boundary\n",
        "def plot_svm_boundary(X, y, model, title):\n",
        "    h = .02  # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('PCA 1')\n",
        "    plt.ylabel('PCA 2')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_svm_boundary(X_test, y_test, clf, title=\"SVM Linear Kernel Decision Boundary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aB8gTJ_W5L8"
      },
      "outputs": [],
      "source": [
        "# Train the best model again (poly with degree 4)\n",
        "best_clf = SVC(kernel='poly', degree=4)\n",
        "best_clf.fit(X_train, y_train)\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display it\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix - SVM (poly, degree=4)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IuMvJIm72AF"
      },
      "source": [
        "# XGBOOST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEIsH7wwsw8S"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXYXp_ni8EEB"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Fit\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # For ROC curve\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_prob))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVyrZ4DmzmLc"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Y8L6yEzlLA"
      },
      "outputs": [],
      "source": [
        "# Step 1: Save your DataFrame to a CSV file\n",
        "train.to_csv('modified_dataset.csv', index=False)\n",
        "\n",
        "# Step 2: Download it to your local machine\n",
        "from google.colab import files\n",
        "files.download('modified_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcr4irjP28wi"
      },
      "source": [
        "We run a heatmap to see if logistic regression is going to performgood results on our dataset, through the correlation between the dumy vaiables and the target variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8njnqmU4THf"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-gs_3wD0c_M"
      },
      "outputs": [],
      "source": [
        "corr = train.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a3W3uwHM7dO"
      },
      "source": [
        "we notice that the target variable \"survived\" is highly correlated with the features : cancer stage, smoking status and family history (negatively), and highly positively correlated to the treatement type combined\n",
        "The features: treatement_type_combined is highly correlated with treatement_type_surgery and treatement_type_Radiation what may cnfuse the  logreg model, so since we can  conclude treatement_type_combined  through the other features we'll combine all of them into one catigorical column having tha values ( surgery , radiation and combined )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wIEq99tinRU"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gMrb2FnexHU"
      },
      "outputs": [],
      "source": [
        "features1 = features.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y02OVICee6A-"
      },
      "outputs": [],
      "source": [
        "features1.drop(columns=['treatment_type_Combined'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQxM2-RFivgY"
      },
      "outputs": [],
      "source": [
        "corr = features1.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqD8gB7qjMli"
      },
      "outputs": [],
      "source": [
        "X1_train, X1_test, y_train, y_test = train_test_split(features1, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensions de l'ensemble d'entraînement :\", X1_train.shape, y_train.shape)\n",
        "print(\"Dimensions de l'ensemble de test :\", X1_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoouYjwC_BGF"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "logreg.fit(X1_train, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred = logreg.predict(X1_test)\n",
        "y_prob = logreg.predict_proba(X1_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNtjsaGMBgmX"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpgxiC0RlEHn"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a trained model called 'model'\n",
        "print(\"Coefficients: \", logreg.coef_)\n",
        "print(\"Intercept: \", logreg.intercept_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxL-tqs6jwqp"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report :\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Matrice de confusion\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Prédiction\")\n",
        "plt.ylabel(\"Vérité terrain\")\n",
        "plt.title(\"Matrice de confusion\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7d7lcx_j9Ys"
      },
      "outputs": [],
      "source": [
        "# Courbe ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"Taux de faux positifs\")\n",
        "plt.ylabel(\"Taux de vrais positifs\")\n",
        "plt.title(\"Courbe ROC\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}